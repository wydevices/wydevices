# -*- coding: utf-8 -*- 
#
# Description:
#
# TF1Replay RRS Browser Class Definitions
#
#
#
# Changes:
#
# 2012-04-22
# Initial Commit
#
# 2012-10-05
# Fix September 2012 website/player modification
#
#
# Thanks to Team XBMC Passion for TF1 Replay plugin
# Algos and key are extracted from it.
# Thanks also to https://github.com/monsieurvideo/get-flash-videos/blob/master/lib/FlashVideo/Site/Wat.pm for key
#
# Copyright 2010-2012, WyDev Team.
# Author: Polo35 (polo35580@hotmail.fr)
#
# Licenced under Academic Free License version 3.0
# Review WyGui README & LICENSE files for further details.


import sys
import os
import re
import time
import md5
import urllib
import urllib2
import datetime
import simplejson as json
from pygui.config import user_config
from BeautifulSoup import BeautifulSoup
from peewee.debug import PRINT_EXCEPTION, GET_LOGGER

log = GET_LOGGER(__name__)



WEBSITE = "http://videos.tf1.fr"
WATSITE = "http://www.wat.fr"
CATEGORIES = {"JT":"/programmes-tv-info/video-integrale/",
							"Magazines":"/magazine/video-integrale/",
							"Séries - Fictions":"/series-tv/video-integrale/",
							"Jeux":"/jeux-tv/video-integrale/",
							"Jeunesse":"/programmes-tv-jeunesse/video-integrale/",
							"Divertissement":"/emissions-tv/video-integrale/",
							"Téléfilms":"/telefilms/video-integrale/",
							"Sports":"/sport/video-integrale/"}
# LibAvFormat UserAgent
USERAGENT = "Lavf52.1.0"



class Episode:
	thumbnail = ""
	url_path = ""
	program = ""
	title = ""



class TF1ReplayBrowser(object):

	def __init__(self):
		self.timestamp = datetime.datetime.now()
		return None

	def must_be_refresh(self):
		delta = datetime.datetime.now() - self.timestamp
		limit = user_config['video']['tvreplay_refresh_rate'] * 60
		if delta.seconds > limit:
			return True
		else:
			return False

	def decode_title(self, title):
		return BeautifulSoup(title.encode('utf-8'),convertEntities="html").prettify()
	
	def get_categories(self):
		return [dict(title=title, url_path=url_path) for title, url_path in CATEGORIES.items()]

	def get_subcategories(self, url_path):
		subcategories = list()
		url = urllib.urlopen(WEBSITE + url_path)
		html = url.read()
		url.close()

		#Search episodes without teasers
		soup = BeautifulSoup(html)    
		teasers = soup.find('li',{'class': re.compile(r'\bteaser\b')}).parent.findAll('li')
		if len(teasers)>0:
			episodes = list()
			for teaser in teasers:
				ep = Episode()
				ep.thumbnail = teaser.find('img')['src']
				detail = teaser.find('h3', {'class': re.compile(r'\btitre\b') })
				ep.title = detail.find('a').renderContents()
				ep.url_path = detail.find('a')['href']
				program = teaser.find('div', {'class': re.compile(r'\bprog\b') })
				if program:
					ep.program = program.strong.renderContents()
				episodes.append(ep)

		# Search next page
		next_page = re.search("""<li class="suivante c4 t3"><a onmousedown="sjs\(this,'#([^']*)'\)" [^>]*>\s*Suivant""",html)
		if next_page:
			next_page = next_page.group(1).replace('|','/')
		else:
			next_page = None

		# Add episodes to subcategories list
		for ep in episodes:
			if WEBSITE in ep.url_path:
				url_path = ep.url_path
			else:
				url_path = WEBSITE + ep.url_path
			if ep.program != "":
				subcategories.append(dict(title=self.decode_title(ep.program + " - " + ep.title), thumbnail=ep.thumbnail, url_path=url_path))
			else:
				subcategories.append(dict(title=self.decode_title(ep.title), thumbnail=ep.thumbnail, url_path=url_path))

		return next_page, subcategories
	
	def get_products(self, url_path):
		try:
			req = urllib2.Request(url_path)
			req.add_header('User-Agent', USERAGENT)
			url = urllib2.urlopen(req)
			response = url.read()
			url.close()
			video_id = re.compile('mediaId :(.*?),').findall(response)[0].strip(' ')
			video_path = WATSITE + '/interface/contentv3/' + video_id
			content = urllib2.Request(video_path)
			content.add_header('User-Agent', USERAGENT)
			url = urllib2.urlopen(content)
			jsonVideoInfos = url.read()
			url.close()
			videoInfos = json.loads(jsonVideoInfos)
			return dict(title=self.decode_title(videoInfos['media'].get('title')), thumbnail=videoInfos['media'].get('preview'), url_path=url_path)
		except Exception, e:
			PRINT_EXCEPTION(e)
		return None

	def get_chapters(self, url_path):
		try:
			req = urllib2.Request(url_path)
			req.add_header('User-Agent', USERAGENT)
			url = urllib2.urlopen(req)
			response = url.read()
			url.close()
			video_id = re.compile('mediaId :(.*?),').findall(response)[0].strip(' ')
			content = urllib2.Request(WATSITE + '/interface/contentv3/' + video_id)
			content.add_header('User-Agent', USERAGENT)
			url = urllib2.urlopen(content)
			jsonVideoInfos = url.read()
			url.close()
			videoInfos = json.loads(jsonVideoInfos)
		except Exception, e:
			PRINT_EXCEPTION(e)
			videoInfos = None
		if videoInfos is None:
			return []
		retlist = []
		for chapter in range(len(videoInfos['media']['files'])):
			try:
				video_id = str(videoInfos['media']['files'][chapter].get('id'))
				if videoInfos['media']['files'][chapter].get('hasHD', False) and user_config['video']['tvreplay_hd']:
					wat_url = "/webhd/" + video_id
				else:
					wat_url = "/web/" + video_id
				key = "9b673b13fa4682ed14c3cfa5af5310274b514c4133e9b3a81e6e3aba00912564"
				old_dthex = ''
				# Loop retrying to get real video url.
				# Only http://wak.wat.tv url work for us. So force flash player version to LNX%209,10,122,202
				for retry in range(50):
					# Timestamp in hexa. Make sure it change between retry
					dthex = hex(int(time.time()))[2:]
					while dthex == old_dthex:
						dthex = hex(int(time.time()))[2:]
					old_dthex = dthex
					h = md5.new()
					h.update(key + wat_url + dthex)
					token = h.hexdigest() + "/" + dthex
					# HD switch
					if videoInfos['media']['files'][chapter].get('hasHD', False) and user_config['video']['tvreplay_hd']:
						url4videoPath = WATSITE + "/get/webhd/" + video_id + "?token=" + token + "&domain=videos.tf1.fr&country=FR&context=swf2&getURL=1&version=LNX%209,10,122,202"
					else:
						url4videoPath = WATSITE + "/get/web/" + video_id + "?token=" + token + "&domain=videos.tf1.fr&country=FR&context=swf2&getURL=1&version=LNX%209,10,122,202"
					# This url give the real video url. (Http or Rtmp)
					req = urllib2.Request(url4videoPath)
					req.add_header('User-Agent', USERAGENT)
					url = urllib2.urlopen(req)
					real_url = url.read()
					url.close()
					# Http url
					if real_url.startswith('http://wak.wat.tv'):
						break
					# Rtmp url
					elif real_url.startswith('rtmpe,'):
						def sub_rtmp(attr):
							return attr.group('url') + ":443" + attr.group('app') + attr.group('playpath')
						real_url = re.sub(r'(?P<url>.*.tv)(?P<app>.*.)(?P<playpath>.mp4:*.*)(?P<end>.bu=*.*)', sub_rtmp, real_url[6:])
						break
					log.debug("Not a wak.wat.tv url. Retrying")
				else:
					real_url = ''
				retlist.append(dict(title=self.decode_title(videoInfos['media']['chapters'][chapter].get('title')),
														thumbnail=videoInfos['media']['chapters'][chapter].get('preview'),
														uri=real_url))
			except Exception, e:
				PRINT_EXCEPTION(e)
		return retlist

if ( __name__ == "__main__" ):
	import sys
	TF1Replay_Client = TF1ReplayBrowser()
	if (len(sys.argv) > 1):
		category = dict()
		if sys.argv[1].isdigit():
			cat_num = int(sys.argv[1])
			category['title'], category['url_path'] = CATEGORIES.items()[cat_num]
		else:
			cat = sys.argv[1]
			category['title'] = cat
			category['url_path'] = CATEGORIES.get(cat)
		print 'Category'
		print 'Title   : ', category['title']
		next_page, subcategories = TF1Replay_Client.get_subcategories(category['url_path'])
		for subcategory in subcategories:
			print 'Sub Category'
			print 'Title    : ', subcategory['title']
			print 'Thumbnail: ', subcategory['thumbnail']
			print 'Url Path : ', subcategory['url_path']
			product = TF1Replay_Client.get_products(subcategory['url_path'])
			if product is None:
				continue
			print 'Product'
			print 'Title    : ', product['title']
			print 'Thumbnail: ', product['thumbnail']
			print 'Url Path : ', product['url_path']
			chapters = TF1Replay_Client.get_chapters(product['url_path'])
			if chapters is None:
				continue
			for chapter in chapters:
				print 'Chapter'
				print 'Title    : ', chapter['title']
				print 'Thumbnail: ', chapter['thumbnail']
				print 'Uri      : ', chapter['uri']
		# Test next page
		print 'Next Page  : ', next_page
		if next_page is not None:
			next_page, subcategories = TF1Replay_Client.get_subcategories(next_page)
			for subcategory in subcategories:
				print 'Sub Category'
				print 'Title    : ', subcategory['title']
				print 'Thumbnail: ', subcategory['thumbnail']
			print 'Next Page  : ', next_page
	else:
		for category in TF1Replay_Client.get_categories():
			print 'Category'
			print 'Title   : ', category['title']
			next_page, subcategories = TF1Replay_Client.get_subcategories(category['url_path'])
			for subcategory in subcategories:
				print 'Sub Category'
				print 'Title    : ', subcategory['title']
				print 'Thumbnail: ', subcategory['thumbnail']
				print 'Url Path : ', subcategory['url_path']
				product = TF1Replay_Client.get_products(subcategory['url_path'])
				if product is None:
					continue
				print 'Product'
				print 'Title    : ', product['title']
				print 'Thumbnail: ', product['thumbnail']
				print 'Url Path : ', product['url_path']
				chapters = TF1Replay_Client.get_chapters(product['url_path'])
				if chapters is None:
					continue
				for chapter in chapters:
					print 'Chapter'
					print 'Title    : ', chapter['title']
					print 'Thumbnail: ', chapter['thumbnail']
					print 'Uri      : ', chapter['uri']
			# Test next page
			print 'Next Page  : ', next_page
			if next_page is not None:
				next_page, subcategories = TF1Replay_Client.get_subcategories(next_page)
				for subcategory in subcategories:
					print 'Sub Category'
					print 'Title    : ', subcategory['title']
					print 'Thumbnail: ', subcategory['thumbnail']
				print 'Next Page  : ', next_page
