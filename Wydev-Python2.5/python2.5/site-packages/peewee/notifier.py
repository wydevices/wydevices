# -*- coding: utf-8 -*- 
#
# Description:
#
# Peewee Notifier Class Definitions
#
#
#
# Changes:
#
# 2011-12-06
# Initial Commit
#
#
# Copyright 2010-2014, WyDev Team.
# Author: Polo35 (polo35580@hotmail.fr)
#
# Licenced under Academic Free License version 3.0
# Review WyGui README & LICENSE files for further details.


from __future__ import absolute_import, with_statement

__all__ = ['Event', 'CleverEvent', 'Task', 'Timer', 'OneShotTimer', 'events_watch', 'descriptor_watch', 'sched', 'loop', 'stop', 'GlobalTimer', 'global_timer']

import collections
import threading
import select
import errno
import time as _time
from heapq import heapify, heappop, heappush
from peewee.debug import GET_LOGGER, TRACE, PRINT_EXCEPTION
from peewee.gettime import time

log = GET_LOGGER(__name__)



# Named events
# One can subscribe events and be notified when they are post()ed
class Event(object):

	__slots__ = ['name', 'arg']
	watchers = []
	drop_all = False

	def __init__(self, name):
		self.name = name
		return None

	def __str__(self):
		return self.name

	def __hash__(self):
		return self.name

	def __cmp__(self, other):
		return cmp(self.name, other.name)

	def __eq__(self, other):
		return self.name == other.name

	# Post an event
	# arg: dict with a timeout property
	def post(self, arg=None):
		if not Event.drop_all:
			if arg is not None:
				Task(self._post, arg).start(0, timeout=arg['timeout'])
			else:
				Task(self._post, arg).start(0, timeout=None)
		return None

	def _post(self, arg=None):
		self.arg = arg
		for watcher in self.watchers:
			watcher(self)
		return None



# Like Event but handle repeat internally
class CleverEvent(object):

	__slots__ = ['name', 'arg', '_stop_task', '_loop_task', '_count', 'repeat', 'timeout', 'accels']
	watchers = []
	drop_all = False

	def __init__(self, name, repeat=0.10000000000000001, timeout=0.13, accels=None):
		self.name = name
		self.repeat = repeat
		self._loop_task = Task(self._repeat)
		self._stop_task = Task(self._loop_task.stop)
		self._count = 0
		return None

	def __str__(self):
		return self.name

	def __hash__(self):
		return self.name

	def __cmp__(self, other):
		return cmp(self.name, other.name)

	def __eq__(self, other):
		return self.name == other.name

	# Post an event
	# arg: dict with a timeout property
	def post(self, arg=None):
		if not Event.drop_all:
			self._loop_task.args = [arg]
			if not self._loop_task.running:
				self._count = 0
				self._loop_task.start(delay=self.repeat, init_delay=0.01, loop=True)
				self._stop_task.start(self.timeout)
			else:
				self._stop_task.start(self.timeout)
		return None

	def _repeat(self, arg):
		self._count += 1
		if 'timeout' in arg and arg['timeout'] is not None:
			timeout = arg['timeout'] + self.repeat
		else:
			timeout = None
		Task(self._post, arg).start(0, timeout=timeout)
		try:
			self._loop_task.ival = self.accels[self._count]
		except:
			self._loop_task.ival = self.repeat
		return None

	def _post(self, arg=None):
		self.arg = arg
		self.arg['count'] = self._count
		for watcher in self.watchers:
			watcher(self)
		return None



# Control events dropping.
# Used for mtp mode
def events_drop(bool):
	Event.drop_all = bool
	CleverEvent.drop_all = bool
	return None



# Be notified when an event is posted
# The callback is called with the event as only parameter.
def events_watch(callback):
	Event.watchers.append(callback)
	CleverEvent.watchers.append(callback)
	return None



# Be notified when a descriptor has something to read
# The callback is called without parameter.
def descriptor_watch(fd, callback):
	sched._rfds[fd].append(callback)
	return None



# Make callback start after 'idle_threshold' seconds of inactivity
# WARNING: only one callback allowed for now
def set_idle_callback(callback, exit_callback, idle_threshold=10):
	sched._idle_infos['on_enter'] = callback
	sched._idle_infos['on_exit'] = exit_callback
	sched._idle_infos['threshold'] = idle_threshold
	return None



# Decorator that makes the target callable run in a Task.
#
# Useful for e.g. dbus callbacks that are called in a separate thread.
#
# If you're stacking decorators with side effects, @tasked should be
# the outermost decorator. Otherwise the code from the outer decorators
# will be called before the actual function code, and there will *not*
# be much rejoicing.
#
# Usage:
#  >>> @tasked(0.1)
#  >>> def foo(*args, **kw):
#  ...     pass
#  >>> # Run foo in a Task with a 0.1s delay
#  >>> foo(bar, baz, fnord=None)
#
# /!\\ WARNING /!\\ Do *not* use on instance methods that are likely
# to be called at the same time with different arguments in different threads.
# Interference between the calls may occur if that happens
# (e.g. all calls but one being ignored).
# Yes, that'll be painful to debug, so don't do that, okay?
class tasked(object):

	def __init__(self, delay):
		self.task = Task(None)
		self.task.delay = delay
		return None

	def __call__(self, fn):
		self.task.fn = fn
		def decorated(*args, **kw):
			log.debug('Starting Task for %s', self.task.fn)
			self.task.args, self.task.kw = args, kw
			self.task.start()
			return None
		decorated.task = self.task
		return decorated



# A schedulable task.
# Interesting properties:
# running (bool): is the task running ?
# delay: base delay (interval in loop mode)
#
# Exemples:
# Will start task after 5s and then every second
# task.start(1, loop=True, init_delay=5)
# Start a task & stop it before anything
# t = Task(sys.stdout.write, 'Hello world\\n').start(5)
# t.stop()
# 
# Implementation Notes:
# Two tasks started within the same task and with the same delay will
# be scheduled for the *same* time be cause the reference time is the
# begin of the current task.
# The probability for another task to be executed between those two tasks is very very low.
class Task(object):

	__slots__ = ['args', 'kw', 'fn', 'running', 'timeout', 'delay', 'ival', '_paused', '_generator', '_considered_idle']

	# fn: the call associated to this task
	# *args & **kw: arguments passed to callable fn
	def __init__(self, fn, *args, **kw):
		self.args = args
		self.kw = kw
		self.fn = fn
		self.ival = None
		self.running = False
		self.timeout = None
		self._generator = None
		self._considered_idle = False
		return None

	def __repr__(self):
		return '<%s %s task %s calling %s>' % (('running' if self.running else 'stopped'), ('idle' if self._considered_idle else 'busy'), ('once' if self.ival is None else 'every %ss' % self.ival), self.fn)

	# Starts a task, every parameter is optional
	# Params:
	#     delay: executes the task after delay (seconds)
	#         NOTE: the delay is relative to the start of the current task
	#         (so try to keep small tasks)
	#     loop: repeat the task every delay (bool)
	#     timeout: drop the task if can't be run within timeout (seconds)
	#     init_delay: *first* delay, useful if different from repeat delay in loop mode (seconds)
	#     consider_idle: If False (default behavior), the Task will stop
	#         the screensaver or prevent it from launching when it is run.
	#         Otherwise, it won't interfere with the screensaver.
	# Returns: self
	def start(self, delay=None, loop=None, timeout=None, init_delay=None, consider_idle=None):
		if self.running:
			self.stop()
		self.running = sched.ts
		self._paused = None
		if consider_idle is not None:
			self._considered_idle = consider_idle
		if loop is None:
			if self.ival is None:
				loop = False
			else:
				loop = True
		if delay is None:
			delay = self.delay
		if delay is None:
			delay = 1.0
		self.delay = delay
		if timeout is not None:
			self.timeout = timeout
		if not loop:
			self.ival = None
		else:
			self.ival = delay
		self._generator = self._generate()
		sched.add(self, (init_delay if init_delay is not None else delay), self._generator)
		return self

	# Pause a task, no calls are done after this
	def pause(self):
		if self._paused is None:
			self._paused = sched.ts - self.running
			self.stop()
			return self._paused
		return None

	# Resume a paused task, preserving the remaining time before execution
	def unpause(self):
		if self._paused is not None:
			self.running = sched.ts
			self._generator = self._generate()
			remaining = self.delay - self._paused
			sched.add(self, remaining, self._generator)
			self._paused = None
			return remaining
		return None

	# Stop a task, preventing any scheduled calls to occur
	def stop(self):
		self.running = False
		if self._generator is not None:
			try:
				self._generator.close()
			except ValueError:
				log.warning('%s has running timer!', self)
			self._generator = None
			sched.remove(self)
		return None

	def _generate(self):
		while True:
			ret = None
			try:
				ret = self.fn(*self.args, **self.kw)
			except StopIteration:
				break
			except Exception, e:
				PRINT_EXCEPTION(e)
				log.error('Task failed: %s: %s' % (self, e))
				TRACE()
			finally:
				if not self.running:
					yield None
			if ret.__class__ is float:
				yield ret
			yield self.ival



# This class provide a Thread skeleton, typically in order
# to be started by a ThreadedTask object.
# The main method, which is executed in run() is func_process(), that MUST
# be overriden.
# Control methods are available, and are called when func_process succeded, or failed,
# or is canceled, and to retrieve some infos
# !!! In order to be canceled, func_process has to be asynchronous
class HookThread(threading.Thread):

	def __init__(self):
		threading.Thread.__init__(self)
		self.completed = threading.Event()
		self.started = threading.Event()
		return None

	def run(self):
		try:
			self.func_process()
			self.completed.wait()
			log.debug('completed set !')
		except Exception:
			self.on_failure()
		else:
			self.on_success()
		return None

	# The main method that MUST be overriden
	def func_process(self, *args, **kw):
		raise NotImplementedError

	# If useful, provides a hook to retrieve some infos at a given moment
	def get_infos(self):
		return None

	# Called automatically when the job is canceled (at least, MUST set the flag Event to 'set')
	def on_cancel(self):
		log.debug(self)
		self.completed.set()
		return None

	# Called automatically if func_process has ended without exception
	def on_success(self):
		log.debug(self)
		try:
			self.controler.stop()
		except AttributeError:
			pass
		return None

	# Called automatically if func_process has ended with exception
	def on_failure(self):
		log.debug(self)
		try:
			self.controler.stop()
		except AttributeError:
			pass
		return None



# This class provides a Task that mainly do 2 things :
#   - start the HookThread object passed in parameters and control it
#   - retrieves infos on this HookThread and report them via progress method()
class ThreadedTask(Task):

	def __init__(self, job, *args, **kw):
		Task.__init__(self, fn=None)
		self.job = job
		self.job.controler = self
		self.fn = self._get_job_infos
		return None

	def __repr__(self):
		return '<%s %s task %s getting infos from %s>' % (('running' if self.running else 'stopped'), ('idle' if self._considered_idle else 'busy'), ('once' if self.ival is None else 'every %ss' % self.ival), self.__class__.__name__)

	def start(self, delay=None, loop=True, timeout=None, init_delay=None, consider_idle=None):
		self.job.start()
		Task.start(self, delay, loop, timeout, init_delay, consider_idle)
		return None

	# Permit formatting infos job (for example, display progress in a progress bar)
	def report_job_progress(self, infos_dict):
		return None

	def _get_job_infos(self):
		self.report_job_progress(self.job.get_infos())
		return None

	# Called to terminate a ThreadedTask.
	# When overriden, do your stuff BEFORE calling stop()
	def on_terminate(self):
		return None

	def cancel(self):
		job = self.job
		try:
			job.on_cancel()
			log.debug('Thread %r canceled', job)
		except Exception, e:
			log.error('Unable to cancel Thread %r <==%s==>', job, e)
		finally:
			self.stop()
		return None

	def stop(self):
		self.on_terminate()
		Task.stop(self)
		return None



# GlobalTimer is in charge to handle global tasks in notifier.
# Tasks can be added and are accesible by a simple name.
# Callbacks can be registered, and so executed each time the task ticks.
class GlobalTimer(object):

	def __init__(self):
		self._indexed_tasks = {}
		self._global_tasks = collections.defaultdict(dict)
		self.add('clock', self.global_clock, delay=1, loop=True, consider_idle=True)
		return None

	# Return for one task_name, all registered callbacks
	def callbacks_by_task(self, task_name):
		return self._global_tasks[self._indexed_tasks[task_name]]

	# Add callback 'obs' for task_name.
	# This callback will be called each time task_name is executed.
	def register_callback(self, task_name, obs, *args, **kw):
		self.callbacks_by_task(task_name)[obs] = (args, kw)
		return None

	# Remove callback 'obs' from task_name.
	def unregister_callback(self, task_name, obs):
		self.callbacks_by_task(task_name).pop(obs)
		return None

	# Add a new task named by task_name in global timer.
	# This task can execute a function if fn is not None. If the function is provided,
	# it is executed before calling dispatcher.
	# If fn is None, only dispatcher is called.
	def add(self, task_name, fn=None, args=None, kwargs=None, delay=0, loop=None, timeout=None, init_delay=None, consider_idle=None):
		if fn is not None:
			if args is not None:
				args = args
			else:
				args = tuple()
			if kwargs is not None:
				kwargs = kwargs
			else:
				kwargs = {}
			def _fn():
				log.debug('GlobalTimer: %s' % task_name)
				ret = fn(*args, **kwargs)
				self._dispatch(task_name, ret)
				return None
			t = Task(_fn)
		else:
			t = Task(self._dispatch, task_name)
		self._indexed_tasks[task_name] = t
		self._global_tasks[t] = {}
		t.start(delay, loop, timeout, init_delay, consider_idle)
		return None

	# Remove task_name from global timer (of course, the task is stopped first)
	def remove(self, task_name):
		t = self._indexed_tasks.pop(task_name)
		t.stop()
		self._global_tasks.pop(t)
		return None

	# Stop the global timer, by stopping all registered tasks
	def stop(self):
		for task in self._indexed_tasks.itervalues():
			task.stop()
		self._indexed_tasks.clear()
		self._global_tasks.clear()
		return None

	# 'Private' method in charge to call all callbacks registered for task_name.
	# Called each time task_name is executed.
	# If 'ret' argument is provided, it becomes first argument for the callback.
	def _dispatch(self, task_name, ret=None):
		log.debug('GlobalTimer: %s' % task_name)
		for obs, (args, kw) in self.callbacks_by_task(task_name).iteritems():
			if ret is not None:
				obs(ret, *args, **kw)
			else:
				obs(*args, **kw)
		return None

	def global_clock(self):
		return _time.time()



# The scheduler, should not be manipulated directly.
# For now, one is created and is the default one.
class Scheduler(object):

	def __init__(self):
		self.ts = time()
		self._tasks = []
		self.granularity = 0.01
		self._rfds = collections.defaultdict((lambda : []))
		self._idle_infos = dict(threshold=10, on_enter=None, on_exit=None, running=False)
		return None

	def add(self, task, ival, gen):
		heappush(self._tasks, (self.ts + ival - self.granularity, task, gen))
		return None

	def remove(self, task):
		_found = []
		for i, (tm, t, g) in enumerate(self._tasks):
			if t is task:
				_found.append(i)
		if _found:
			for f in reversed(_found):
				self._tasks.pop(f)
			heapify(self._tasks)
		return None

	# Stops the scheduler, the loop() call will return nicely after some delay
	def stop(self):
		self._running = False
		return None

	# Schedules tasks ad vitam aeternam until stop() is called
	def loop(self):
		tasks = self._tasks
		delta = self.granularity
		add = self.add
		self._running = True
		empty_list = []
		idle_since = self.ts
		while self._running:
			self.ts = time()
			if tasks and tasks[0][0] < self.ts:
				(delay, task, generator) = heappop(tasks)
				if task.timeout is not None and self.ts > task.timeout:
					log.warn('Dropped task: %s (+%s)', task, self.ts - task.timeout)
				else:
					try:
						if not task.running:
							raise StopIteration
						if not task._considered_idle:
							idle_since = self.ts
						log.info('TASK> %s', task)
						ival = generator.next()
						log.info('<TASK done in %.3ss' % (time() - self.ts))
					except StopIteration:
						continue
					if ival is not None:
						sched.add(task, ival, task._generator)
					else:
						task.running = False
			else:
				try:
					for rfd in select.select(self._rfds.keys(), empty_list, empty_list, delta)[0]:
						for r in self._rfds[rfd]:
							r()
				except select.error, v:
					if v[0] != errno.EINTR:
						raise v
				idle_value = int(self.ts - idle_since)
				if not self._idle_infos['running']:
					if self._idle_infos['threshold'] <= idle_value:
						cb = self._idle_infos['on_enter']
						if cb:
							cb()
						self._idle_infos['running'] = True
				elif idle_value < self._idle_infos['threshold']:
					if self._idle_infos['running']:
						cb = self._idle_infos['on_exit']
						if cb:
							cb()
						self._idle_infos['running'] = False
		return None



sched = Scheduler()
loop = sched.loop
stop = sched.stop
global_timer = GlobalTimer()



def main():
	import itertools
	i = itertools.count()
	def nop():
		return None

	def killer():
		stop()
		return None

	def call_count():
		i.next()
		never_called.start()
		return None

	Task(killer).start(2)
	Task(call_count).start(0, loop=True)
	never_called = Task(nop).start(1)
	loop()
	num_iter = i.next()
	sched._tasks = []
	print num_iter
	return num_iter

if __name__ == '__main__':
	ref = 722
	NB_ITER = 10
	avg = sum((main() for x in xrange(NB_ITER))) / NB_ITER
	print 'Average: %d [~ %d tasks per second|overhead: %.2e] (%d %%, <100%% means slower)' % (avg, avg * 2.8599999999999999, 1.0 / avg * 2.8599999999999999, avg * 100.0 / ref)



OneShotTimer = Task



# DEPRECATED: use Task with loop=True
class Timer(Task):

	__slots__ = ['args', 'kw', 'fn', 'stopped', 'timeout', 'delay', 'ival', '_paused', '_generator', '_considered_idle']

	def start(self, delay=None, loop=True, **kw):
		log.warn('Use of Timer is DEPRECATED, please use a Task started with loop=True.')
		TRACE()
		Task.start(self, delay, loop, **kw)
		return None
